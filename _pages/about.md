---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a first-year CS Ph.D. at Stanford University, currently working with Professor [Stefano Ermon](https://cs.stanford.edu/~ermon/). Before that, I received my B.S. in Math and Computer Science at Yuanpei College, Peking University, under the advice of Professor [Liwei Wang](http://www.liweiwang-pku.com/) and [Di He](https://dihe-pku.github.io/). 
<br/>
<br/>
I am interested in making machine learning tools more powerful in scientific problems through theories, algorithms design, and high performance computing. If you are interested in my research, please feel free to contact me!

News
======
- (Feb. 2024) Our [Forward Laplacian paper](https://www.nature.com/articles/s42256-024-00794-x) is accepted by Nature Machine Intelligence! We release [LapJAX](https://github.com/YWolfeee/lapjax), a JAX based package designed for accelerating general second order operators (e.g., Laplacian) computation.

Selected Publications
======
- **(Nature Machine Intelligence) A computational framework for neural network-based variational Monte Carlo with Forward Laplacian**
  <br/>
  _Ruichen Li\*, Haotian Ye\*, Du Jiang, Xuelan Wen, Chuwei Wang, Zhe Li, Xiang Li, Di He, Ji Chen, Weiluo Ren, Liwei Wang_
  <br/>
  [[Paper](https://www.nature.com/articles/s42256-024-00794-x)]
- **(NeurIPS 2023, Oral) Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective**
  <br/>
  _Guhao Feng\*, Bohang Zhang\*, Yuntian Gu\*, Haotian Ye\*, Di He, Liwei Wang_
  <br/>
  [[Paper](https://arxiv.org/abs/2305.15408)]
  [[Video](https://youtu.be/nOIRuVluCyE)]
  [[Slides](https://haotianye.com/files/NeurIPS23/Slides_NeurIPS23_CoT.pdf)]
- **(ICML 2023, Oral) On the Power of Pre-training for Generalization in RL: Provable Benefits and Hardness**
  <br/>
  _Haotian Ye\*, Xiaoyu Chen\*, Liwei Wang, Simon Shaolei Du_
  <br/>
  [[Paper](https://arxiv.org/abs/2210.10464)]
- **(AISTATS 2023) Freeze then Train: Towards Provable Representation Learning under Spurious Correlations and Feature Noise**
  <br/>
  _Haotian Ye, James Zou, Linjun Zhang_
  <br/>
  [[Paper](https://arxiv.org/abs/2210.11075)]
  [[Code](https://github.com/YWolfeee/Freeze-Then-Train)]
  [[Video](https://www.youtube.com/watch?v=K9evpKADRpk)]
  [[Slides](https://haotianye.com/files/AISTATS23/slides_AISTATS23_FTT.pdf)]
- **(ICLR 2023) Discovering Latent Knowledge in Language Models Without Supervision**
  <br/>
  _Collin Burns\*, Haotian Ye\*, Dan Klein, Jacob Steinhardt_
  <br/>
  [[Paper](https://arxiv.org/abs/2212.03827)]
- **(J. Chem. Phys. Aug 2023) DeePMD-kit v2: A software package for Deep Potential models**
  <br/>
  _Jinzhe Zeng, Duo Zhang, ..., Haotian Ye, ..., Weinan E, Roberto Car, Linfeng Zhang, Han Wang_
  <br/>
  [[Paper](https://doi.org/10.1063/5.0155600)]
- **(NeurIPS 2021) Towards a Theoretical Framework of Out-of-Distribution Generalization**
  <br/>
  _Haotian Ye\*, Chuanlong Xie, Tianle Cai, Ruichen Li, Zhenguo Li, Liwei Wang_
  <br/>
  [[Paper](https://arxiv.org/abs/2106.04496)]
  [[Code](https://github.com/YWolfeee/DomainBed)]
  [[Video](https://slideslive.com/38967497/towards-a-theoretical-framework-of-outofdistribution-generalization?ref=recommended)]
  [[Slides](http://haotianye.com/files/NeurIPS21/slides_NeurIPS21_OOD.pdf)]


Selected Awards
======
- Weiming Scholar of Peking University (1%), 2023
- [Person of the Year](http://m.cyol.com/gb/articles/2021-12/28/content_XM2l5spYg.html) of Peking University (10 people/year), 2021
- May 4 scholarship (1%, Rank 1), 2021
- National scholarship (1%, Rank 2), 2019
- Leo Koguan scholarship (1%), 2020
- Merit student pacesetter (2%), 2019
- Chinese Mathematical Olympiad (First Prize, Rank 7 in China), 2017

<a href='https://clustrmaps.com/site/1bpcz'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=ffffff&w=600&t=tt&d=H_rmQ74PzdkUNlANtUmgRXjPSpOOYZFUaRnZHpKaXyE'/></a>
